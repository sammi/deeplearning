{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实战 Kaggle 比赛：狗的品种识别 (ImageNet Dogs)\n",
    "\n",
    "\n",
    "我们将在本节动手实战 Kaggle 比赛中的狗的品种识别问题。该比赛的网页地址是\n",
    "\n",
    "> https://www.kaggle.com/c/dog-breed-identification\n",
    "\n",
    "在这个比赛中，我们将识别 120 类不同品种的狗。这个比赛的数据集实际上是著名的 ImageNet 的子集数据集。和上一节的 CIFAR-10 数据集中的图像不同，ImageNet 数据集中的图像更高更宽，且大小不一。\n",
    "\n",
    "图 9.18 展示了该比赛的网页信息。为了便于提交结果，请先在 Kaggle 网站上注册账号。\n",
    "\n",
    "![狗的品种识别比赛的网页信息。比赛数据集可通过点击“Data”标签获取](../img/kaggle-dog.png)\n",
    "\n",
    "\n",
    "首先，导入实验所需的包或模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import gluonbook as gb\n",
    "import math\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, model_zoo, nn\n",
    "import os\n",
    "import shutil\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数据集\n",
    "\n",
    "比赛数据分为训练数据集和测试数据集。训练集了包含 10,222 张图像，测试集了包含 10,357 张图像。两个数据集中的图像格式都是 JPEG。这些图像都含有 RGB 三个通道（彩色），高和宽的大小不一。训练集中狗的类别共有 120 种，例如拉布拉多、贵宾、腊肠、萨摩耶、哈士奇、吉娃娃和约克夏等。\n",
    "\n",
    "### 下载数据集\n",
    "\n",
    "登录 Kaggle 后，我们可以点击图 9.18 所示的狗的品种识别比赛网页上的“Data”标签，并分别下载训练数据集“train.zip”、测试数据集“test.zip”和训练数据集标签“label.csv.zip”。下载完成后，将它们分别存放在以下路径：\n",
    "\n",
    "* ../data/kaggle_dog/train.zip\n",
    "* ../data/kaggle_dog/test.zip\n",
    "* ../data/kaggle_dog/labels.csv.zip\n",
    "\n",
    "\n",
    "为方便快速上手，我们提供了上述数据集的小规模采样“train_valid_test_tiny.zip”。如果你要使用上述 Kaggle 比赛的完整数据集，还需要把下面`demo`变量改为`False`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [],
   "source": [
    "# 如果使用下载的 Kaggle 比赛的完整数据集，把下面改为 False。\n",
    "demo = True\n",
    "data_dir = '../data/kaggle_dog'\n",
    "\n",
    "if demo:\n",
    "    zipfiles = ['train_valid_test_tiny.zip']\n",
    "else:\n",
    "    zipfiles = ['train.zip', 'test.zip', 'labels.csv.zip']\n",
    "\n",
    "for f in zipfiles:\n",
    "    with zipfile.ZipFile(data_dir + '/' + f, 'r') as z:\n",
    "        z.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整理数据集\n",
    "\n",
    "我们定义下面的`reorg_dog_data`函数来整理 Kaggle 比赛的完整数据集。经过整理后，同一类狗的图像将被放在同一个文件夹下，便于我们稍后读取。\n",
    "该函数中的参数`valid_ratio`是验证集中每类狗的样本数与原始训练集中数量最少一类的狗的样本数（66）之比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    }
   },
   "outputs": [],
   "source": [
    "def reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir, \n",
    "                   valid_ratio):\n",
    "    # 读取训练数据标签。\n",
    "    with open(os.path.join(data_dir, label_file), 'r') as f:\n",
    "        # 跳过文件头行（栏名称）。\n",
    "        lines = f.readlines()[1:]\n",
    "        tokens = [l.rstrip().split(',') for l in lines]\n",
    "        idx_label = dict(((idx, label) for idx, label in tokens))\n",
    "\n",
    "    # 训练集中数量最少一类的狗的样本数。\n",
    "    min_n_train_per_label = (\n",
    "        collections.Counter(idx_label.values()).most_common()[:-2:-1][0][1])\n",
    "    # 验证集中每类狗的样本数。\n",
    "    n_valid_per_label = math.floor(min_n_train_per_label * valid_ratio)\n",
    "    label_count = {}\n",
    "\n",
    "    def mkdir_if_not_exist(path):\n",
    "        if not os.path.exists(os.path.join(*path)):\n",
    "            os.makedirs(os.path.join(*path))\n",
    "\n",
    "    # 整理训练和验证集。\n",
    "    for train_file in os.listdir(os.path.join(data_dir, train_dir)):\n",
    "        idx = train_file.split('.')[0]\n",
    "        label = idx_label[idx]\n",
    "        mkdir_if_not_exist([data_dir, input_dir, 'train_valid', label])\n",
    "        shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                    os.path.join(data_dir, input_dir, 'train_valid', label))\n",
    "        if label not in label_count or label_count[label] < n_valid_per_label:\n",
    "            mkdir_if_not_exist([data_dir, input_dir, 'valid', label])\n",
    "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                        os.path.join(data_dir, input_dir, 'valid', label))\n",
    "            label_count[label] = label_count.get(label, 0) + 1\n",
    "        else:\n",
    "            mkdir_if_not_exist([data_dir, input_dir, 'train', label])\n",
    "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                        os.path.join(data_dir, input_dir, 'train', label))\n",
    "\n",
    "    # 整理测试集。\n",
    "    mkdir_if_not_exist([data_dir, input_dir, 'test', 'unknown'])\n",
    "    for test_file in os.listdir(os.path.join(data_dir, test_dir)):\n",
    "        shutil.copy(os.path.join(data_dir, test_dir, test_file),\n",
    "                    os.path.join(data_dir, input_dir, 'test', 'unknown'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于我们在这里使用了小数据集，所以将批量大小设为 1。在实际训练和测试时，我们应使用 Kaggle 比赛的完整数据集并调用`reorg_dog_data`函数整理数据集。相应地，我们也需要将批量大小`batch_size`设为一个较大的整数，例如 128。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [],
   "source": [
    "if demo:\n",
    "    # 注意：此处使用小数据集并将批量大小相应设小。使用 Kaggle 比赛的完整数据集时可设批量大\n",
    "    # 小为较大整数。\n",
    "    input_dir, batch_size = 'train_valid_test_tiny', 1\n",
    "else:\n",
    "    label_file, train_dir, test_dir = 'labels.csv', 'train', 'test'\n",
    "    input_dir, batch_size, valid_ratio = 'train_valid_test', 128, 0.1\n",
    "    reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir, \n",
    "                   valid_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像增广\n",
    "\n",
    "为应对过拟合，我们在这里使用`transforms`来增广数据集。例如，加入`transforms.RandomFlipLeftRight()`即可随机对图像做镜面翻转。我们也通过`transforms.Normalize()`对彩色图像的 RGB 三个通道分别做标准化。以下列举了其中的部分操作。你可以根据需求来决定是否使用或修改这些操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [],
   "source": [
    "transform_train = gdata.vision.transforms.Compose([\n",
    "    # 随机对图像裁剪出面积为原图像面积 0.08 到 1 倍之间、且高和宽之比在 3/4 和 4/3 之间\n",
    "    # 的图像，再放缩为高和宽均为 224 像素的新图像。\n",
    "    gdata.vision.transforms.RandomResizedCrop(224, scale=(0.08, 1.0),\n",
    "                                              ratio=(3.0/4.0, 4.0/3.0)),\n",
    "    # 随机左右翻转图像。\n",
    "    gdata.vision.transforms.RandomFlipLeftRight(),\n",
    "    # 随机抖动亮度、对比度和饱和度。\n",
    "    gdata.vision.transforms.RandomColorJitter(brightness=0.4, contrast=0.4,\n",
    "                                              saturation=0.4),\n",
    "    # 随机加噪音。\n",
    "    gdata.vision.transforms.RandomLighting(0.1),\n",
    "    \n",
    "    # 将图像像素值按比例缩小到 0 和 1 之间，并将数据格式从“高 * 宽 * 通道”改为\n",
    "    # “通道 * 高 * 宽”。\n",
    "    gdata.vision.transforms.ToTensor(),\n",
    "    # 对图像的每个通道做标准化。\n",
    "    gdata.vision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                      [0.229, 0.224, 0.225])])\n",
    "\n",
    "# 测试时，只使用确定性的图像预处理操作。\n",
    "transform_test = gdata.vision.transforms.Compose([\n",
    "    gdata.vision.transforms.Resize(256),\n",
    "    # 将图像中央的高和宽均为 224 的正方形区域裁剪出来。\n",
    "    gdata.vision.transforms.CenterCrop(224),\n",
    "    gdata.vision.transforms.ToTensor(),\n",
    "    gdata.vision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                      [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们可以使用`ImageFolderDataset`类来读取整理后的数据集，其中的每个数据样本均包括图像和标签。需要注意的是，我们要在`DataLoader`中调用刚刚定义好的图像增广函数，其中的`transform_first`函数指明对每个数据样本中的图像做数据增广。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    }
   },
   "outputs": [],
   "source": [
    "# 读取原始图像文件。flag=1 说明输入图像有三个通道（彩色）。\n",
    "train_ds = gdata.vision.ImageFolderDataset(\n",
    "    os.path.join(data_dir, input_dir, 'train'), flag=1)\n",
    "valid_ds = gdata.vision.ImageFolderDataset(\n",
    "    os.path.join(data_dir, input_dir, 'valid'), flag=1)\n",
    "train_valid_ds = gdata.vision.ImageFolderDataset(\n",
    "    os.path.join(data_dir, input_dir, 'train_valid'), flag=1)\n",
    "test_ds = gdata.vision.ImageFolderDataset(\n",
    "    os.path.join(data_dir, input_dir, 'test'), flag=1)\n",
    "\n",
    "train_data = gdata.DataLoader(train_ds.transform_first(transform_train),\n",
    "                              batch_size, shuffle=True, last_batch='keep')\n",
    "valid_data = gdata.DataLoader(valid_ds.transform_first(transform_test),\n",
    "                              batch_size, shuffle=True, last_batch='keep')\n",
    "train_valid_data = gdata.DataLoader(train_valid_ds.transform_first(\n",
    "    transform_train), batch_size, shuffle=True, last_batch='keep')\n",
    "test_data = gdata.DataLoader(test_ds.transform_first(transform_test),\n",
    "                             batch_size, shuffle=False, last_batch='keep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型并使用微调\n",
    "\n",
    "这个比赛的数据属于 ImageNet 数据集的子集，因此我们可以使用[“微调”](fine-tuning.md)一节中介绍的思路，选用在 ImageNet 完整数据集上预训练过的模型，并通过微调在比赛数据集上进行训练。Gluon 提供了丰富的预训练模型，我们在这里以预训练过的 ResNet-34 模型为例。由于比赛数据集属于预训练数据集的子集，因此我们可以重用预训练模型在输出层的输入（即特征），并将原输出层替换成新的可以训练的小规模输出网络，例如两个串联的全连接层。由于预训练模型的参数在训练中是固定的，我们既节省了训练它们的时间，又节省了存储它们的梯度所需的空间。\n",
    "\n",
    "需要注意的是，我们在图像增广中使用了 ImageNet 数据集上 RGB 三个通道的均值和标准差做标准化，这和预训练模型所做的标准化是一致的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    }
   },
   "outputs": [],
   "source": [
    "def get_net(ctx):\n",
    "    # 设 pretrained=True 就能获取预训练模型的参数。第一次使用时需要联网下载。\n",
    "    finetune_net = model_zoo.vision.resnet34_v2(pretrained=True)\n",
    "    # 定义新的输出网络。\n",
    "    finetune_net.output_new = nn.HybridSequential(prefix='')\n",
    "    finetune_net.output_new.add(nn.Dense(256, activation='relu'))\n",
    "    # 120 是输出的类别数。\n",
    "    finetune_net.output_new.add(nn.Dense(120))\n",
    "    # 初始化输出网络。\n",
    "    finetune_net.output_new.initialize(init.Xavier(), ctx=ctx)\n",
    "    # 把模型参数分配到即将用于计算的 CPU 或 GPU 上。\n",
    "    finetune_net.collect_params().reset_ctx(ctx)\n",
    "    return finetune_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练函数\n",
    "\n",
    "我们将依赖模型在验证集上的表现来选择模型并调节超参数。模型的训练函数`train`只会训练我们定义的输出网络。我们记录了每个迭代周期的训练时间，这有助于比较不同模型的时间开销。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    }
   },
   "outputs": [],
   "source": [
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "def get_loss(data, net, ctx):\n",
    "    l = 0.0\n",
    "    for X, y in data:\n",
    "        y = y.as_in_context(ctx)\n",
    "        # 计算预训练模型输出层的输入，即特征。\n",
    "        output_features = net.features(X.as_in_context(ctx))\n",
    "        # 将特征作为我们定义的输出网络的输入，计算输出。\n",
    "        outputs = net.output_new(output_features)\n",
    "        l += loss(outputs, y).mean().asscalar()\n",
    "    return l / len(data)\n",
    "\n",
    "def train(net, train_data, valid_data, num_epochs, lr, wd, ctx, lr_period,\n",
    "          lr_decay):\n",
    "    # 只训练我们定义的输出网络。\n",
    "    trainer = gluon.Trainer(net.output_new.collect_params(), 'sgd',\n",
    "                            {'learning_rate': lr, 'momentum': 0.9, 'wd': wd})\n",
    "    prev_time = datetime.datetime.now()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l = 0.0\n",
    "        if epoch > 0 and epoch % lr_period == 0:\n",
    "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "        for X, y in train_data:\n",
    "            y = y.astype('float32').as_in_context(ctx)\n",
    "            # 计算预训练模型输出层的输入，即特征。\n",
    "            output_features = net.features(X.as_in_context(ctx))\n",
    "            with autograd.record():\n",
    "                # 将特征作为我们定义的输出网络的输入，计算输出。\n",
    "                outputs = net.output_new(output_features)\n",
    "                l = loss(outputs, y)\n",
    "            # 反向传播只发生在我们定义的输出网络上。\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_l += l.mean().asscalar()\n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_s = \"time %02d:%02d:%02d\" % (h, m, s)\n",
    "        if valid_data is not None:\n",
    "            valid_loss = get_loss(valid_data, net, ctx)\n",
    "            epoch_s = (\"epoch %d, train loss %f, valid loss %f, \"\n",
    "                       % (epoch + 1, train_l / len(train_data), valid_loss))\n",
    "        else:\n",
    "            epoch_s = (\"epoch %d, train loss %f, \"\n",
    "                       % (epoch + 1, train_l / len(train_data)))\n",
    "        prev_time = cur_time\n",
    "        print(epoch_s + time_s + ', lr ' + str(trainer.learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练并验证模型\n",
    "\n",
    "现在，我们可以训练并验证模型了。以下的超参数都是可以调节的，例如增加迭代周期等。由于`lr_period`和`lr_decay`分别设为 10 和 0.1，优化算法的学习率将在每 10 个迭代周期后自乘 0.1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss 5.193722, valid loss 4.783684, time 00:00:03, lr 0.01\n"
     ]
    }
   ],
   "source": [
    "ctx, num_epochs, lr, wd = gb.try_gpu(), 1, 0.01, 1e-4\n",
    "lr_period, lr_decay, net = 10, 0.1, get_net(ctx)\n",
    "net.hybridize()\n",
    "train(net, train_data, valid_data, num_epochs, lr, wd, ctx, lr_period,\n",
    "      lr_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对测试集分类并在 Kaggle 提交结果\n",
    "\n",
    "当得到一组满意的模型设计和超参数后，我们使用全部训练数据集（含验证集）重新训练模型，并对测试集分类。注意，我们要用刚训练好的输出网络做预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss 5.044901, time 00:00:06, lr 0.01\n"
     ]
    }
   ],
   "source": [
    "net = get_net(ctx)\n",
    "net.hybridize()\n",
    "train(net, train_valid_data, None, num_epochs, lr, wd, ctx, lr_period,\n",
    "      lr_decay)\n",
    "\n",
    "preds = []\n",
    "for data, label in test_data:\n",
    "    # 计算预训练模型输出层的输入，即特征。\n",
    "    output_features = net.features(data.as_in_context(ctx))\n",
    "    # 将特征作为我们定义的输出网络的输入，计算输出。\n",
    "    output = nd.softmax(net.output_new(output_features))\n",
    "    preds.extend(output.asnumpy())\n",
    "ids = sorted(os.listdir(os.path.join(data_dir, input_dir, 'test/unknown')))\n",
    "with open('submission.csv', 'w') as f:\n",
    "    f.write('id,' + ','.join(train_valid_ds.synsets) + '\\n')\n",
    "    for i, output in zip(ids, preds):\n",
    "        f.write(i.split('.')[0] + ',' + ','.join(\n",
    "            [str(num) for num in output]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行完上述代码后，会生成一个“submission.csv”文件。这个文件符合 Kaggle 比赛要求的提交格式。这时我们可以在 Kaggle 上把对测试集分类的结果提交并查看分类准确率。你需要登录 Kaggle 网站，访问 ImageNet Dogs 比赛网页，并点击右侧“Submit Predictions”或“Late Submission”按钮。然后，点击页面下方“Upload Submission File”选择需要提交的分类结果文件。最后，点击页面最下方的“Make Submission”按钮就可以查看结果了。\n",
    "\n",
    "\n",
    "## 小结\n",
    "\n",
    "* 我们可以使用在 ImageNet 数据集上预训练的模型并微调，从而以较小的计算开销对 ImageNet 的子集数据集做分类。\n",
    "\n",
    "\n",
    "## 练习\n",
    "\n",
    "* 使用 Kaggle 完整数据集，把批量大小`batch_size`和迭代周期数`num_epochs`分别调大些，可以在 Kaggle 上拿到什么样的结果？\n",
    "* 使用更深的预训练模型并微调，你能获得更好的结果吗？\n",
    "* 扫码直达讨论区，在社区交流方法和结果。你能发掘出其他更好的技巧吗？\n",
    "\n",
    "## 扫码直达[讨论区](https://discuss.gluon.ai/t/topic/2399)\n",
    "\n",
    "![](../img/qr_kaggle-gluon-dog.svg)\n",
    "\n",
    "## 参考文献\n",
    "\n",
    "[1] Kaggle ImageNet Dogs 比赛网址。https://www.kaggle.com/c/dog-breed-identification"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}