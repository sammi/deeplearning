{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get alert history for all devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "import os\n",
    "import sys\n",
    "from mxnet.gluon import data as gdata\n",
    "from mxnet.io import NDArrayIter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data_alerts(batch_size):\n",
    "    train_data = np.array(pd.read_csv('./data/alert/train.csv').values)\n",
    "    test_data = np.array(pd.read_csv('./data/alert/test.csv').values)\n",
    "    \n",
    "    num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "    \n",
    "    train_iter = gdata.DataLoader(train_data, batch_size, shuffle=True, num_workers=num_workers)\n",
    "    \n",
    "    test_iter = gdata.DataLoader(test_data, batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
=======
    "from mxnet import nd\n",
    "from mxnet.gluon.data import DataLoader\n",
    "from mxnet.gluon.data.dataset import ArrayDataset\n",
    "from multiprocessing import cpu_count\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data_alerts_from_csv(batch_size):\n",
    "    num_workers = 0\n",
    "    features = ['f1', 'f2', 'f3', 'f4']\n",
    "    label = ['a']\n",
    "\n",
    "    train_features = pd.read_csv('./data/alert/train.csv', usecols=features).values\n",
    "    train_labels = pd.read_csv('./data/alert/train.csv', usecols=label).values\n",
    "\n",
    "    test_features  = pd.read_csv('./data/alert/test.csv', usecols=features).values\n",
    "    test_labels  = pd.read_csv('./data/alert/test.csv', usecols=label).values\n",
    "\n",
    "    train_iter = DataLoader(\n",
    "        ArrayDataset(train_features.astype('float32'), train_labels),\n",
    "        shuffle=True,\n",
    "        batch_size = batch_size,\n",
    "        num_workers= num_workers\n",
    "    )\n",
    "\n",
    "    test_iter = DataLoader(\n",
    "        ArrayDataset(test_features.astype('float32'), test_labels),\n",
    "        batch_size = batch_size,\n",
    "        num_workers= num_workers\n",
    "    )\n",
    "    \n",
>>>>>>> 26677540fadbfc0fd71dacdb8c080af8c0ff4e9c
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import autograd, nd\n",
    "\n",
<<<<<<< HEAD
    "num_inputs = 4\n",
    "num_outputs = 3\n",
    "batch_size = 2\n",
    "\n",
    "train_iter, test_iter = load_data_alerts(batch_size)\n",
=======
    "num_inputs  = 4\n",
    "num_outputs = 3\n",
    "batch_size = 200\n",
    "\n",
    "train_iter, test_iter = load_data_alerts_from_csv(batch_size)\n",
>>>>>>> 26677540fadbfc0fd71dacdb8c080af8c0ff4e9c
    "\n",
    "W = nd.random.normal(scale=0.01, shape=(num_inputs, num_outputs))\n",
    "b = nd.zeros(num_outputs)\n",
    "params = [W, b]\n",
    "\n",
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    X_exp = nd.exp(X)\n",
    "    partition = X_exp.sum(axis=1, keepdims=True)\n",
    "    return X_exp / partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    return softmax(nd.dot(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return - nd.pick(y_hat, y).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(axis=1) == y.astype('float32')).mean().asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc = 0.\n",
<<<<<<< HEAD
    "    for batch in data_iter:\n",
    "        X = batch[:, :num_inputs]\n",
    "        y = batch[:, num_inputs]\n",
    "        acc += accuracy(net(X), y)\n",
=======
    "    for X, y in data_iter:\n",
    "        y_hat = net(X)\n",
    "        acc += accuracy(y_hat, y)\n",
>>>>>>> 26677540fadbfc0fd71dacdb8c080af8c0ff4e9c
    "    return acc / len(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[17:08:22] c:\\jenkins\\workspace\\mxnet-tag\\mxnet\\src\\io\\../operator/elemwise_op_common.h:133: Check failed: assign(&dattr, (*vec)[i]) Incompatible attr in node  at 1-th input: expected int64, got float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d0fc8d851c3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-126bae595b77>\u001b[0m in \u001b[0;36mevaluate_accuracy\u001b[1;34m(data_iter, net)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0macc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-9fbe401ca7f0>\u001b[0m in \u001b[0;36mnet\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\sandbox\\lib\\site-packages\\mxnet\\ndarray\\register.py\u001b[0m in \u001b[0;36mdot\u001b[1;34m(lhs, rhs, transpose_a, transpose_b, forward_stype, out, name, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\sandbox\\lib\\site-packages\\mxnet\\_ctypes\\ndarray.py\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[1;34m(handle, ndargs, keys, vals, out)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         ctypes.byref(out_stypes)))\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moriginal_output\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\sandbox\\lib\\site-packages\\mxnet\\base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \"\"\"\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMXNetError\u001b[0m: [17:08:22] c:\\jenkins\\workspace\\mxnet-tag\\mxnet\\src\\io\\../operator/elemwise_op_common.h:133: Check failed: assign(&dattr, (*vec)[i]) Incompatible attr in node  at 1-th input: expected int64, got float32"
     ]
    }
   ],
   "source": [
    "evaluate_accuracy(test_iter, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
=======
>>>>>>> 26677540fadbfc0fd71dacdb8c080af8c0ff4e9c
   "outputs": [],
   "source": [
    "def SGD(params, learning_rate):\n",
    "    for param in params:\n",
    "        param[:] = param - learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import autograd\n",
    "\n",
    "num_epochs, learning_rate = 5, .01\n",
=======
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Loss: 0.253841, Train acc 0.376531, Test acc 0.375000\n",
      "Epoch 2. Loss: 0.253290, Train acc 0.375464, Test acc 0.375000\n",
      "Epoch 3. Loss: 0.252785, Train acc 0.377044, Test acc 0.375000\n",
      "Epoch 4. Loss: 0.252242, Train acc 0.376303, Test acc 0.375000\n",
      "Epoch 5. Loss: 0.251707, Train acc 0.376017, Test acc 0.375000\n",
      "Epoch 6. Loss: 0.251189, Train acc 0.377811, Test acc 0.375000\n",
      "Epoch 7. Loss: 0.250662, Train acc 0.376586, Test acc 0.375000\n",
      "Epoch 8. Loss: 0.250131, Train acc 0.375758, Test acc 0.375000\n",
      "Epoch 9. Loss: 0.249614, Train acc 0.377053, Test acc 0.375000\n",
      "Epoch 10. Loss: 0.249112, Train acc 0.377717, Test acc 0.375000\n",
      "Epoch 11. Loss: 0.248589, Train acc 0.376319, Test acc 0.375000\n",
      "Epoch 12. Loss: 0.248066, Train acc 0.376147, Test acc 0.375000\n",
      "Epoch 13. Loss: 0.247574, Train acc 0.378006, Test acc 0.375000\n",
      "Epoch 14. Loss: 0.247034, Train acc 0.375275, Test acc 0.375000\n",
      "Epoch 15. Loss: 0.246529, Train acc 0.376419, Test acc 0.375000\n",
      "Epoch 16. Loss: 0.246022, Train acc 0.375794, Test acc 0.375000\n",
      "Epoch 17. Loss: 0.245540, Train acc 0.377222, Test acc 0.375000\n",
      "Epoch 18. Loss: 0.245034, Train acc 0.377717, Test acc 0.375000\n",
      "Epoch 19. Loss: 0.244521, Train acc 0.376675, Test acc 0.375000\n",
      "Epoch 20. Loss: 0.244024, Train acc 0.377228, Test acc 0.375000\n",
      "Epoch 21. Loss: 0.243513, Train acc 0.376594, Test acc 0.375000\n",
      "Epoch 22. Loss: 0.243031, Train acc 0.377372, Test acc 0.375000\n",
      "Epoch 23. Loss: 0.242557, Train acc 0.380311, Test acc 0.375000\n",
      "Epoch 24. Loss: 0.242025, Train acc 0.377742, Test acc 0.375000\n",
      "Epoch 25. Loss: 0.241537, Train acc 0.377056, Test acc 0.375000\n",
      "Epoch 26. Loss: 0.241050, Train acc 0.377131, Test acc 0.375000\n",
      "Epoch 27. Loss: 0.240570, Train acc 0.378194, Test acc 0.375000\n",
      "Epoch 28. Loss: 0.240071, Train acc 0.376992, Test acc 0.375000\n",
      "Epoch 29. Loss: 0.239566, Train acc 0.375803, Test acc 0.375000\n",
      "Epoch 30. Loss: 0.239080, Train acc 0.376567, Test acc 0.375000\n",
      "Epoch 31. Loss: 0.238613, Train acc 0.376331, Test acc 0.375000\n",
      "Epoch 32. Loss: 0.238124, Train acc 0.375936, Test acc 0.375000\n",
      "Epoch 33. Loss: 0.237636, Train acc 0.375872, Test acc 0.375000\n",
      "Epoch 34. Loss: 0.237173, Train acc 0.376056, Test acc 0.375000\n",
      "Epoch 35. Loss: 0.236705, Train acc 0.378031, Test acc 0.375000\n",
      "Epoch 36. Loss: 0.236214, Train acc 0.375869, Test acc 0.375000\n",
      "Epoch 37. Loss: 0.235748, Train acc 0.376792, Test acc 0.375000\n",
      "Epoch 38. Loss: 0.235277, Train acc 0.376389, Test acc 0.375000\n",
      "Epoch 39. Loss: 0.234810, Train acc 0.376617, Test acc 0.375000\n",
      "Epoch 40. Loss: 0.234334, Train acc 0.376192, Test acc 0.375000\n",
      "Epoch 41. Loss: 0.233870, Train acc 0.376497, Test acc 0.375000\n",
      "Epoch 42. Loss: 0.233403, Train acc 0.376219, Test acc 0.375000\n",
      "Epoch 43. Loss: 0.232928, Train acc 0.375625, Test acc 0.375000\n",
      "Epoch 44. Loss: 0.232486, Train acc 0.376778, Test acc 0.375000\n",
      "Epoch 45. Loss: 0.232032, Train acc 0.377525, Test acc 0.375000\n",
      "Epoch 46. Loss: 0.231555, Train acc 0.376194, Test acc 0.375000\n",
      "Epoch 47. Loss: 0.231090, Train acc 0.375867, Test acc 0.375000\n",
      "Epoch 48. Loss: 0.230652, Train acc 0.377936, Test acc 0.375000\n",
      "Epoch 49. Loss: 0.230210, Train acc 0.378100, Test acc 0.375000\n",
      "Epoch 50. Loss: 0.229745, Train acc 0.377131, Test acc 0.375000\n"
     ]
    }
   ],
   "source": [
    "from mxnet import autograd\n",
    "\n",
    "num_epochs, learning_rate = 50, 0.001\n",
>>>>>>> 26677540fadbfc0fd71dacdb8c080af8c0ff4e9c
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    for batch in train_iter:\n",
    "        with autograd.record():\n",
    "            X = batch[:, :num_inputs]\n",
    "            y = batch[:, num_inputs]\n",
    "            y_hat = net(X)\n",
    "            loss = cross_entropy(y_hat, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        SGD(params, learning_rate / batch_size)\n",
    "        \n",
    "        train_loss += loss.mean().asscalar()\n",
    "        train_acc += accuracy(y_hat, y)\n",
    "        \n",
    "    test_acc = evaluate_accuracy(test_iter, net)\n",
    "\n",
    "    print(\"Epoch %d. Loss: %f, Train acc %f, Test acc %f\" % (\n",
    "        epoch + 1, train_loss/len(train_iter), train_acc/len(train_iter), test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " [[-0.03750757  0.05224912  0.02555499]\n",
       "  [-0.09017095  0.07088293  0.0376971 ]\n",
       "  [-0.16210105  0.05490853  0.09076232]\n",
       "  [-0.20533222  0.04711026  0.11781221]]\n",
       " <NDArray 4x3 @cpu(0)>, \n",
       " [-0.03962177  0.2298372  -0.19021544]\n",
       " <NDArray 3 @cpu(0)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
