{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "(<mxnet.gluon.data.dataloader.DataLoader at 0x17d0a452e48>,\n",
       " <mxnet.gluon.data.dataloader.DataLoader at 0x17d0a452eb8>)"
=======
       "(<mxnet.gluon.data.dataloader.DataLoader at 0x7f997981c160>,\n",
       " <mxnet.gluon.data.dataloader.DataLoader at 0x7f997981c1d0>)"
>>>>>>> 26677540fadbfc0fd71dacdb8c080af8c0ff4e9c
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gluonbook as gb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from mxnet.gluon import data as gdata\n",
    "from mxnet.gluon.data import DataLoader\n",
    "from mxnet.gluon.data.dataset import ArrayDataset\n",
    "from mxnet.io import NDArrayIter\n",
    "\n",
    "train_data = np.array(pd.read_csv('./data/alert/train.csv').values)\n",
    "test_data = np.array(pd.read_csv('./data/alert/test.csv').values)\n",
    "\n",
    "batch_size = 2\n",
    "num_inputs = 4\n",
    "num_outputs = 3\n",
    "num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "\n",
    "train_iter = NDArrayIter(\n",
    "    data={'data': train_data[:, 0:num_inputs]},\n",
    "    label={'softmax_label': train_data[:, num_inputs]},\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_iter = NDArrayIter(\n",
    "    data={'data': test_data[:, 0:num_inputs]},\n",
    "    label={'softmax_label': test_data[:, num_inputs]},\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "\n",
    "# train_iter = DataLoader(\n",
    "#     ArrayDataset(train_data[:, 0:num_inputs], train_data[:, num_inputs]),\n",
    "#     batch_size = batch_size,\n",
    "#     num_workers= num_workers\n",
    "# )\n",
    "\n",
    "# test_iter = DataLoader(\n",
    "#     ArrayDataset(test_data[:, 0:num_inputs], test_data[:, num_inputs]),\n",
    "#     batch_size = batch_size,\n",
    "#     num_workers= num_workers\n",
    "# )\n",
    "\n",
    "train_iter, test_iter = gb.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "\n",
    "(train_iter, test_iter)\n",
    "\n",
    "# for feature, label in test_iter:\n",
    "#     print(feature.shape, label.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon, init, autograd\n",
    "from mxnet.gluon import loss as gloss, nn\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(num_outputs))\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.5062, train acc 0.262, test acc 0.262\n",
      "epoch 2, loss 0.4841, train acc 0.265, test acc 0.203\n",
      "epoch 3, loss 0.4860, train acc 0.266, test acc 0.244\n",
      "epoch 4, loss 0.4784, train acc 0.266, test acc 0.275\n",
      "epoch 5, loss 0.4686, train acc 0.267, test acc 0.282\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "gb.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
